{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d326d1",
   "metadata": {},
   "source": [
    "In this notebook, we will write our own k-means model from scratch and use it to cluster handwritten numbers from the MNIST dataset\n",
    "\n",
    "In the cell below, we create an assign_data function, which takes the data and the centers for each cluster and makes an assignment of each datapoint in data to the closest of the centers, centerids. We extract n, the number of datapoints, d, the dimensionality of the datapoints, and k the number of centers.\n",
    "\n",
    "Next, we need to compute the squared distance between each center and each data point.\n",
    "\n",
    "Reshaping the data to be 1 x n x d, and the centers to be k x 1 x d signals to numpy that when it subtracts these two arrays, it creates an array of shape k x n x d. That is, it computes all combinations of the k centers and the n datapoints for each of the d dimensions. We assign those differences to res.\n",
    "\n",
    "Squaring each of the differences, then summing along dimension 2 --- that’s the components of the vectors --- produces the sum of squared distances, which is the squared distance between the centers and the datapoints. The resulting array is of shape k x n.\n",
    "\n",
    "assign_data also computes the loss, which the sum of the squared differences. We want to know which center has the smallest squared distance for each data point. argmin produces the index of an array with the smallest value along the given dimension. Here, we’re using dimension 0, which varies over the k centers. centerids is now an array with one integer for each datapoint that indicates which of the centers is closest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10080de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_data(data,centers):\n",
    "  # n is the number of data points\n",
    "    n = len(data)\n",
    "  # d is the dimensionality of the data points\n",
    "    d = len(data[0])\n",
    "  # k is the number of clusters\n",
    "    k = len(centers)\n",
    "  # first, subtract the set of centers from each data point\n",
    "    res = np.reshape(data,(1,n,d))-np.reshape(centers,(k,1,d))\n",
    "  # sum the squared differences\n",
    "    res2 = np.add.reduce(res**2,2)\n",
    "  # assign each data point to its closest center\n",
    "    centerids = np.apply_along_axis(np.argmin,0,res2)\n",
    "  # While we're here, make a note of the loss\n",
    "    loss = sum(np.apply_along_axis(np.min,0,res2))\n",
    "return(centerids, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa05b45",
   "metadata": {},
   "source": [
    "Next we'll compute the mean of each of the k centers using the data and their centerids assignments. compute_means takes the data and the center ids and computes the centers by averaging all of the datapoints with the same id. This will be used to update the centers.\n",
    "\n",
    "After extracting the number of datapoints and dimension, we initialize the array of center locations to a k x d array of all zeros.\n",
    "\n",
    "For each of the cluster id values from 0 to k, we do the following operations:\n",
    "\n",
    "First, form a smaller array, cols, consisting of all the datapoints with the current center id.\n",
    "To be robust, we make sure cols has a length greater than zero. That can happen if there’s a center that has been elbowed out of the running by the other centers being closer to all of the data points.\n",
    "If it equals zero, that means our center is out of the action and we should probably pick a different location for it. We simply choose one of the data points at random to be this new location.\n",
    "We want to move the center to the mean of the closest points. Numpy’s mean method computes the average of an array along any given dimension. Here, we choose dimension 0, which corresponds to the different data points. mean produces a component-wise average of all the data points with cluster id equal to i.\n",
    "After completing the loop, we return the newly computed centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bedb342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_means(data, centerids, k):\n",
    "    # n is number of data points\n",
    "    n = len(data)\n",
    "    # d is dimensionality of the data points\n",
    "    d = len(data[0])\n",
    " \n",
    "    # Zero out the centers\n",
    "    centers = np.zeros(shape=(k,d))\n",
    " \n",
    "  # loop over the clusters\n",
    "    for i in range(k):\n",
    "    # Gather the data points assigned to cluster i\n",
    "    cols = np.array([data[j] for j in range(n) if centerids[j] == i])\n",
    "    # Average to get mean for that cluster\n",
    "    if len(cols) == 0: \n",
    "        centers[i] = data[random.randint(0,n-1)]\n",
    "    else:\n",
    "        centers[i] = cols.mean(0)\n",
    "    return(centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7e9c3",
   "metadata": {},
   "source": [
    "With these two functions, we can build a kmeans model, which takes in the data and number of clusters, k and iteratively builds k clusters and updates them relative to the loss.\n",
    "\n",
    "We initialize the k centers by selecting random data points. We loop until the loss stops changing. If oldloss is different from the new loss, we use assign_data to assign each datapoint to its closest center. Then, we use compute_means to move the centers to the means of the points assigned to them. We repeat until the loss stops changing, returning the final loss and centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9193319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(data, k):\n",
    "    n = len(data)\n",
    "    d = len(data[0])\n",
    "  # grab the centers from random points\n",
    "    centers = data[[random.randint(0,n-1) for i in range(k)]]\n",
    "    oldloss = 0\n",
    "    loss = 1\n",
    "    while oldloss != loss:\n",
    "        oldloss = loss\n",
    "        centerids, loss = assign_data(data,centers)\n",
    "        centers = compute_means(data, centerids, k)\n",
    "    return(centers, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe537ff",
   "metadata": {},
   "source": [
    "We will download the MNIST dataset and split the data into training data, X_train and y_train and test data, X_test and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e653dfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "data = fetch_openml(name='mnist_784')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_test, y_test, test_size=0.33)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f6b63",
   "metadata": {},
   "source": [
    "Here, we run kmeans on our X_train data where k=10. We run kmeans 9 times and record the bestcenters which have the bestloss among the recorded losses. We then find the accuracy of these new centers on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7230a33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6432/3542622293.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;31m# 2 # 5 # 20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mbestcenters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mcenters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6432/2203559982.py\u001b[0m in \u001b[0;36mkmeans\u001b[1;34m(data, k)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[1;31m# grab the centers from random points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcenters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import math\n",
    "from functools import reduce\n",
    "import random\n",
    "\n",
    "#for nlabeled in range(20,len(X_train),10):\n",
    "nlabeled = 20\n",
    "if True:\n",
    "    print(nlabeled)\n",
    "    ans = []\n",
    "    k = 10 # 2 # 5 # 20\n",
    "    if True:\n",
    "        bestcenters, bestloss = kmeans(X_train, k)\n",
    "        for rep in range(9):\n",
    "            centers, loss = kmeans(X_train, k)\n",
    "            if loss < bestloss: bestcenters, bestloss = centers, loss\n",
    "        # How do we test the clustering that was discovered?\n",
    "        # Assign testing points to clusters\n",
    "        test_centerids, loss = assign_data(X_test, bestcenters)\n",
    "\n",
    "        # Use the labeled examples to label the clusters\n",
    "        train_centerids, loss = assign_data(X_train[:nlabeled], bestcenters)\n",
    "        #print(train_centerids)\n",
    "        #print(y_train[:nlabeled])\n",
    "        labs = y_train[:nlabeled]\n",
    "\n",
    "#    clust_labs = np.zeros(shape=(k))\n",
    "        clust_labs = np.repeat(labs[0],k)\n",
    "        for i in range(k):\n",
    "            mode = stats.mode(labs[train_centerids == i]).mode\n",
    "            if len(mode) > 0: clust_labs[i] = mode[0]\n",
    "\n",
    "# print(clust_labs)\n",
    "        ans = ans + [(k,sum(clust_labs[test_centerids] == y_test)/len(y_test))]\n",
    "#    plt.plot(X_test[clust_labs[test_centerids] == 0,0],X_test[clust_labs[test_centerids] == 0,1],'o',color='r')\n",
    "#    plt.plot(X_test[clust_labs[test_centerids] == 1,0],X_test[clust_labs[test_centerids] == 1,1],'o',color='b')\n",
    "#    plt.show()\n",
    "\n",
    "#  print(ans)\n",
    "    print(reduce((lambda x, y: x if x[1] > y[1] else y), ans))\n",
    "    labids, loss = assign_data(X_test, X_train[:nlabeled])\n",
    "    print(nlabeled, sum(y_train[labids] == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a73dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
